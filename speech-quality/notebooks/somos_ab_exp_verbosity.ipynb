{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03fdbc2a-8687-4912-ba35-540a58b14784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8add1ff-7845-4904-bbce-b3b52f47210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49437654-680b-4412-acd1-626438c88d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utteranceId</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ002-0181_110.wav</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ002-0181_148.wav</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ003-0083_177.wav</td>\n",
       "      <td>3.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ003-0173_007.wav</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ003-0173_166.wav</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>wiki_0096_105.wav</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>wiki_0097_061.wav</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>wiki_0098_115.wav</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>wiki_0098_124.wav</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>wiki_0099_056.wav</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             utteranceId      mean\n",
       "0     LJ002-0181_110.wav  4.000000\n",
       "1     LJ002-0181_148.wav  4.000000\n",
       "2     LJ003-0083_177.wav  3.727273\n",
       "3     LJ003-0173_007.wav  3.400000\n",
       "4     LJ003-0173_166.wav  3.000000\n",
       "...                  ...       ...\n",
       "2995   wiki_0096_105.wav  3.714286\n",
       "2996   wiki_0097_061.wav  3.100000\n",
       "2997   wiki_0098_115.wav  2.000000\n",
       "2998   wiki_0098_124.wav  2.333333\n",
       "2999   wiki_0099_056.wav  2.083333\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOS Score\n",
    "test_mos = pd.read_csv(\n",
    "    \"/data/share/data/Speech/somos/training_files/split1/clean/test_mos_list.csv\")\n",
    "test_mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c5c4df-ac31-4ee8-8271-9e76b76ef00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript \n",
    "lines = []\n",
    "# path = \"/data/share/data/Speech/somos/transcript/additional_sentences.txt\"\n",
    "# with open(path) as f:\n",
    "#     for line in f:\n",
    "#         lines.append(line)\n",
    "path = \"/data/share/data/Speech/somos/transcript/all_sentences.txt\"\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        lines.append(line)\n",
    "transcripts = {}\n",
    "for line in lines:\n",
    "    items = line.split('\\t')\n",
    "    assert len(items) == 2\n",
    "    transcripts[items[0]] = items[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e9cd20d-02e0-4224-90a8-b523da223032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e519d7a-fc0b-4b75-b319-1670c479a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "# /data/share/data/Speech/somos/audios/{utteranceId}\n",
    "data = []\n",
    "for i in range(len(test_mos)):\n",
    "    uttId, mos = test_mos['utteranceId'][i], test_mos['mean'][i]\n",
    "    uttId0 = uttId.rsplit('_', 1)[0]\n",
    "    if 'gt_' in uttId0:\n",
    "        uttId0 = uttId0.replace('gt_', '')\n",
    "    path = f\"/data/share/data/Speech/somos/audios/{uttId}\"\n",
    "    assert os.path.exists(path)\n",
    "    assert uttId0 in transcripts\n",
    "    data.append({\n",
    "        'uttId': uttId.replace('.wav', ''),\n",
    "        'mos': mos,\n",
    "        'text': transcripts[uttId0],\n",
    "        'path': path\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75258a01-4995-4c09-933f-645675df4f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wiki_0099', 'wiki_0099_056.wav')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uttId0, uttId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff24365e-5f99-4fa2-aab8-a045845b4004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_mos), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a87485-f2ce-4c38-8a21-f8568f923426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uttId': 'LJ002-0181_110',\n",
       " 'mos': 4.0,\n",
       " 'text': \"to those in other London prisons, for Newgate was not the only place of durance for these unfortunate people. There were also the King's Bench.\",\n",
       " 'path': '/data/share/data/Speech/somos/audios/LJ002-0181_110.wav'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6284170-83e2-4660-8069-afc58e123f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a7ce7-e025-4248-867f-0bfc5f608e8f",
   "metadata": {},
   "source": [
    "# Verbosity\n",
    "- 1 vs 2\n",
    "- 2 vs 3\n",
    "- 3 vs 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d39c0977-c0d9-4f74-931a-5552419b9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_wav(input_path, output_path, repetitions):\n",
    "    \"\"\"\n",
    "    Create a new WAV file by repeating the audio content of the original WAV file N times.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Path to the input WAV file.\n",
    "        output_path (str): Path to save the new WAV file.\n",
    "        repetitions (int): Number of times to repeat the audio.\n",
    "    \"\"\"\n",
    "    # Open the input WAV file\n",
    "    with wave.open(input_path, 'rb') as wav_in:\n",
    "        params = wav_in.getparams()  # Get audio parameters\n",
    "        n_channels = wav_in.getnchannels()\n",
    "        sample_width = wav_in.getsampwidth()\n",
    "        frame_rate = wav_in.getframerate()\n",
    "        n_frames = wav_in.getnframes()\n",
    "\n",
    "        # Read the audio data\n",
    "        audio_data = wav_in.readframes(n_frames)\n",
    "\n",
    "    # Convert audio data to a numpy array\n",
    "    dtype = np.int16 if sample_width == 2 else np.uint8  # Handle 16-bit or 8-bit audio\n",
    "    audio_array = np.frombuffer(audio_data, dtype=dtype)\n",
    "\n",
    "    # Repeat the audio array N times\n",
    "    repeated_audio = np.tile(audio_array, repetitions)\n",
    "\n",
    "    # Convert back to bytes\n",
    "    repeated_audio_bytes = repeated_audio.tobytes()\n",
    "\n",
    "    # Write the repeated audio to the output WAV file\n",
    "    with wave.open(output_path, 'wb') as wav_out:\n",
    "        wav_out.setnchannels(n_channels)\n",
    "        wav_out.setsampwidth(sample_width)\n",
    "        wav_out.setframerate(frame_rate)\n",
    "        wav_out.writeframes(repeated_audio_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb437bb5-c1bf-48da-b3cc-258243823ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31efd9b-8b81-4d7c-be0c-d0a19f8f8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data80 = data[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da3fef05-39e0-405e-889c-23dcaf145eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df9af581-7821-40b1-8788-5e944b6c198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uttId': 'news_2009_0047_196',\n",
       " 'mos': 3.363636363636364,\n",
       " 'text': 'There is never any trouble with Ajax and Celtic fans.',\n",
       " 'path': '/data/share/data/Speech/somos/audios/news_2009_0047_196.wav'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "161805f3-847a-4081-bc41-62c795ac77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 896.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1 vs 2 verbosity\n",
    "verbosity_data = []\n",
    "for x in tqdm(data80):\n",
    "    N = 2\n",
    "    path1 = x['path']\n",
    "    path2 = f\"/data/workspace/ppotsawee/audioLM-as-judge/data/verbosity/repeated_somos/N{N}_{path1.split('/')[-1]}\"\n",
    "    repeat_wav(path1, path2, repetitions=N)\n",
    "    item1 = {\n",
    "        'repetitions': 1,\n",
    "        'path': path1,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    item2 = {\n",
    "        'repetitions': 2,\n",
    "        'path': path2,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    items = [item1, item2]\n",
    "    random.shuffle(items)\n",
    "    verbosity_data.append(items)\n",
    "with open(\"/data/workspace/ppotsawee/audioLM-as-judge/data/data_somos_verbosity_n1n2.json\", \"w\") as f:\n",
    "    json.dump(verbosity_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34cf2e18-b7d4-439c-bed8-6e192a27cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 415.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2 vs 3 verbosity\n",
    "verbosity_data = []\n",
    "for x in tqdm(data80):\n",
    "    path1 = x['path']\n",
    "    path2 = f\"/data/workspace/ppotsawee/audioLM-as-judge/data/verbosity/repeated_somos/N2_{path1.split('/')[-1]}\"\n",
    "    path3 = f\"/data/workspace/ppotsawee/audioLM-as-judge/data/verbosity/repeated_somos/N3_{path1.split('/')[-1]}\"\n",
    "    repeat_wav(path1, path2, repetitions=2)\n",
    "    repeat_wav(path1, path3, repetitions=3)\n",
    "    item3 = {\n",
    "        'repetitions': 3,\n",
    "        'path': path3,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    item2 = {\n",
    "        'repetitions': 2,\n",
    "        'path': path2,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    items = [item3, item2]\n",
    "    random.shuffle(items)\n",
    "    verbosity_data.append(items)\n",
    "with open(\"/data/workspace/ppotsawee/audioLM-as-judge/data/data_somos_verbosity_n2n3.json\", \"w\") as f:\n",
    "    json.dump(verbosity_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ce422d8-9ab1-4836-964a-ef40c02ef9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 469.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3 vs 4 verbosity\n",
    "verbosity_data = []\n",
    "for x in tqdm(data80):\n",
    "    path1 = x['path']\n",
    "    path4 = f\"/data/workspace/ppotsawee/audioLM-as-judge/data/verbosity/repeated_somos/N4_{path1.split('/')[-1]}\"\n",
    "    path3 = f\"/data/workspace/ppotsawee/audioLM-as-judge/data/verbosity/repeated_somos/N3_{path1.split('/')[-1]}\"\n",
    "    repeat_wav(path1, path4, repetitions=4)\n",
    "    repeat_wav(path1, path3, repetitions=3)\n",
    "    item3 = {\n",
    "        'repetitions': 3,\n",
    "        'path': path3,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    item4 = {\n",
    "        'repetitions': 4,\n",
    "        'path': path2,\n",
    "        'text': x['text'],\n",
    "        'mos': x['mos'],\n",
    "        'uttId': x['uttId']\n",
    "    }\n",
    "    items = [item3, item4]\n",
    "    random.shuffle(items)\n",
    "    verbosity_data.append(items)\n",
    "with open(\"/data/workspace/ppotsawee/audioLM-as-judge/data/data_somos_verbosity_n3n4.json\", \"w\") as f:\n",
    "    json.dump(verbosity_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161652f1-41d7-49b3-b7f2-b828eb64adfa",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a174e1e1-0ba0-4ce6-b737-41725b312bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "578ce4ba-84a5-4d03-9589-fcb5a11b92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_file(path):\n",
    "    # path = \"../experiments/somos/ab_testing/diff15_prompt2_verbosity_n1n2.txt\"\n",
    "    outputs = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            x = json.loads(line)\n",
    "            outputs.append(x)\n",
    "    \n",
    "    count_shorter, count_longer, count_tie, count_all = 0, 0, 0, 0\n",
    "    for output in outputs:\n",
    "        audio_a, audio_b = output['data']\n",
    "        judge_text = output['response']\n",
    "    \n",
    "        # typo lol\n",
    "        # judge_text = judge_text.replace(\"</verduct>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"</Verdict>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"</verddict>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"<Verdict>\", \"<verdict>\")\n",
    "        # judge_text = judge_text.replace(\"<verdict>B</verdict>\", \"<verdict>[[B]]</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"Verdict: [[A]] </verdict>\", \"<verdict>[[A]]</verdict>\")\n",
    "        \n",
    "        # Extract content between <verdict> and </verdict>\n",
    "        verdict_match = re.search(r'<verdict>(.*?)</verdict>', judge_text, re.DOTALL)\n",
    "        verdict_text = verdict_match.group(1).strip() if verdict_match else None\n",
    "        assert verdict_text in [\"[[A]]\", \"[[B]]\", \"[[Tie]]\"], f\"Unexpected verdict: {judge_text}\"\n",
    "    \n",
    "        if verdict_text == \"[[A]]\":\n",
    "            if audio_a['repetitions'] > audio_b['repetitions']:\n",
    "                count_longer += 1\n",
    "            else:\n",
    "                count_shorter += 1\n",
    "        elif verdict_text == \"[[B]]\":\n",
    "            if audio_a['repetitions'] < audio_b['repetitions']:\n",
    "                count_longer += 1\n",
    "            else:\n",
    "                count_shorter += 1\n",
    "        else:\n",
    "            count_tie += 1\n",
    "        count_all += 1\n",
    "    print(\"total:\", count_all)\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Shorter: {:.2f}%\".format(count_shorter/count_all*100))\n",
    "    print(\"Tie:     {:.2f}%\".format(count_tie/count_all*100))\n",
    "    print(\"Longer:  {:.2f}%\".format(count_longer/count_all*100))\n",
    "    # return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36fd271c-c220-4550-8e82-24d1188ab00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 80\n",
      "-----------------------\n",
      "Shorter: 60.00%\n",
      "Tie:     2.50%\n",
      "Longer:  37.50%\n"
     ]
    }
   ],
   "source": [
    "read_output_file(\"../experiments/somos/ab_testing/diff15_prompt2_verbosity_n1n2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4acdb2f9-6a2b-4781-a01d-3ca30c8cd5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 80\n",
      "-----------------------\n",
      "Shorter: 62.50%\n",
      "Tie:     0.00%\n",
      "Longer:  37.50%\n"
     ]
    }
   ],
   "source": [
    "read_output_file(\"../experiments/somos/ab_testing/diff15_prompt2_verbosity_n2n3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19fed647-1474-45d9-a51e-1f31f6441fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 80\n",
      "-----------------------\n",
      "Shorter: 73.75%\n",
      "Tie:     1.25%\n",
      "Longer:  25.00%\n"
     ]
    }
   ],
   "source": [
    "read_output_file(\"../experiments/somos/ab_testing/diff15_prompt2_verbosity_n3n4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adac3b-0101-4374-94ca-f07224d0a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
