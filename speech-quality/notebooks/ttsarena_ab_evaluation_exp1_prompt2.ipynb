{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c593004-db35-4c02-9770-e491cf89c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c0022c1-78c7-4566-945c-f281d78e212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_file(path, reverse=False):\n",
    "    # path = \"../experiments/somos/ab_testing/diff15_prompt1.txt\"\n",
    "    outputs = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            x = json.loads(line)\n",
    "            outputs.append(x)\n",
    "    \n",
    "    count_all, count_correct = 0, 0\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "        if not reverse:\n",
    "            audio_a, audio_b = output['data']\n",
    "        else:\n",
    "            audio_b, audio_a = output['data']\n",
    "        \n",
    "        judge_text = output['response']\n",
    "\n",
    "        # typo lol\n",
    "        # judge_text = judge_text.replace(\"</verduct>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"</Verdict>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"</verddict>\", \"</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"<Verdict>\", \"<verdict>\")\n",
    "        # judge_text = judge_text.replace(\"<verdict>B</verdict>\", \"<verdict>[[B]]</verdict>\")\n",
    "        # judge_text = judge_text.replace(\"Verdict: [[A]] </verdict>\", \"<verdict>[[A]]</verdict>\")\n",
    "        judge_text = judge_text.replace(\"```verdict\\n[[A]]\\n```verdict```\", \"<verdict>[[A]]</verdict>\")\n",
    "        judge_text = judge_text.replace(\"```verdict\\n[[B]]\\n```verdict```\", \"<verdict>[[B]]</verdict>\")\n",
    "        judge_text = judge_text.replace(\"Clarity: Audio A was articulate and clear, with minimal distortion or noise, providing good clarity. Audio B was also clear but had minor inconsistencies in articulation.\", \"<verdict>[[A]]</verdict>\")\n",
    "        judge_text = judge_text.replace(\"I'm sorry, I cannot listen to or evaluate the audio files. However, I can help you with other queries or tasks. How can I assist you today?\", \"<verdict>[[B]]</verdict>\")\n",
    "        \n",
    "        \n",
    "        # Extract content between <explanation> and </explanation>\n",
    "        explanation_match = re.search(r'<explanation>(.*?)</explanation>', judge_text, re.DOTALL)\n",
    "        explanation_text = explanation_match.group(1).strip() if explanation_match else None\n",
    "        \n",
    "        # Extract content between <verdict> and </verdict>\n",
    "        verdict_match = re.search(r'<verdict>(.*?)</verdict>', judge_text, re.DOTALL)\n",
    "        verdict_text = verdict_match.group(1).strip() if verdict_match else None\n",
    "        assert verdict_text == \"[[A]]\" or verdict_text == \"[[B]]\", f\"Unexpected verdict: {judge_text}\"\n",
    "\n",
    "        if verdict_text == \"[[A]]\":\n",
    "            if audio_a['mos'] > audio_b['mos']:\n",
    "                count_correct += 1\n",
    "                evaluation = \"correct\"\n",
    "            else:\n",
    "                evaluation = \"incorrect\"\n",
    "        elif verdict_text == \"[[B]]\":\n",
    "            if audio_a['mos'] < audio_b['mos']:\n",
    "                count_correct += 1\n",
    "                evaluation = \"correct\"\n",
    "            else:\n",
    "                evaluation = \"incorrect\"\n",
    "        count_all += 1\n",
    "        \n",
    "        predictions.append([evaluation, verdict_text, audio_a['mos'], audio_b['mos']])\n",
    "    print(\"total:\", count_all)\n",
    "    print(\"accuracy: {:.2f}%\".format(count_correct/count_all*100))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a4e1ce4-ce0d-4f73-8bf4-d9147f5a206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 500\n",
      "accuracy: 53.00%\n"
     ]
    }
   ],
   "source": [
    "predictions_ab = read_output_file(\"../experiments/tts_arena/ab_testing/500_prompt2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6aeab5f-66f7-49a8-856b-11f7e19c501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 500\n",
      "accuracy: 52.40%\n"
     ]
    }
   ],
   "source": [
    "predictions_ba = read_output_file(\"../experiments/tts_arena/ab_testing/500_prompt2_BA.jsonl\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca52dab5-d23d-4278-9839-33ad5abfbcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_A: 33.00%\n",
      "percentage_B: 67.00%\n"
     ]
    }
   ],
   "source": [
    "count_A, count_B, count = 0, 0, 0\n",
    "for x in predictions_ab:\n",
    "    count += 1\n",
    "    if x[1] == \"[[A]]\":\n",
    "        count_A += 1\n",
    "    elif x[1] == \"[[B]]\":\n",
    "        count_B += 1\n",
    "    else:\n",
    "        raise Exception()\n",
    "print(\"percentage_A: {:.2f}%\".format(count_A/count*100))\n",
    "print(\"percentage_B: {:.2f}%\".format(count_B/count*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64959239-aa6e-497f-95f6-ef8df7152df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_A: 38.80%\n",
      "percentage_B: 61.20%\n"
     ]
    }
   ],
   "source": [
    "count_A, count_B, count = 0, 0, 0\n",
    "for x in predictions_ba:\n",
    "    count += 1\n",
    "    if x[1] == \"[[A]]\":\n",
    "        count_A += 1\n",
    "    elif x[1] == \"[[B]]\":\n",
    "        count_B += 1\n",
    "    else:\n",
    "        raise Exception()\n",
    "print(\"percentage_A: {:.2f}%\".format(count_A/count*100))\n",
    "print(\"percentage_B: {:.2f}%\".format(count_B/count*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b065dfdd-cd83-4c5f-b5ca-438a649761a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1000\n",
      "correct: 52.70%\n",
      "incorrect: 47.30%\n"
     ]
    }
   ],
   "source": [
    "abba_correct, abba_incorrect = 0, 0\n",
    "for x in predictions_ab + predictions_ba:\n",
    "    if x[0] == 'correct':\n",
    "        abba_correct += 1\n",
    "    elif x[0] == 'incorrect':\n",
    "        abba_incorrect += 1\n",
    "    else:\n",
    "        raise Exception()\n",
    "print(\"total:\", abba_correct+abba_incorrect)\n",
    "print(\"correct: {:.2f}%\".format(abba_correct/(abba_correct+abba_incorrect)*100))\n",
    "print(\"incorrect: {:.2f}%\".format(abba_incorrect/(abba_correct+abba_incorrect)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f63505bf-74a8-48e7-abfa-3bc9e1affbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ab = predictions_ab[:len(predictions_ba)]\n",
    "consistent, bias_A, bias_B = 0, 0, 0\n",
    "correct_given_consistent = 0\n",
    "for ab, ba in zip(predictions_ab, predictions_ba):\n",
    "    if ab[0] == ba[0]:\n",
    "        consistent += 1\n",
    "        if ab[0] == 'correct':\n",
    "            correct_given_consistent += 1\n",
    "    else:\n",
    "        if ab[1] == \"[[A]]\" and ba[1] == \"[[A]]\":\n",
    "            bias_A += 1\n",
    "        elif ab[1] == \"[[B]]\" and ba[1] == \"[[B]]\":\n",
    "            bias_B += 1\n",
    "        else:\n",
    "            raise Exception(\"logic error\")\n",
    "assert consistent + bias_A + bias_B == len(predictions_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1738ea38-0a94-404b-887e-ea45d35d62b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consistent: 48.60%\n",
      "bias_A:     11.60%\n",
      "bias_B:     39.80%\n",
      "P(correct|consistent): 55.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"consistent: {:.2f}%\".format(consistent/len(predictions_ab)*100))\n",
    "print(\"bias_A:     {:.2f}%\".format(bias_A/len(predictions_ab)*100))\n",
    "print(\"bias_B:     {:.2f}%\".format(bias_B/len(predictions_ab)*100))\n",
    "print(\"P(correct|consistent): {:.2f}%\".format(correct_given_consistent/consistent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac266bf0-96ef-464d-bbc6-d91f0390feaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
