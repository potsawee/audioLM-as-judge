{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257fff71-298a-4a43-8b45-c7c04dd41e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8903436b-8a46-4da6-b1e1-39dcb4e54e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede07d88-9fae-4d86-83aa-3f561ca14bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    # Open and read the file line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse each line as a JSON object\n",
    "            json_obj = json.loads(line.strip())\n",
    "            data.append(json_obj)\n",
    "    print(\"len:\", len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ee9eb9-330c-4806-a942-0a48cc08ecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 654\n"
     ]
    }
   ],
   "source": [
    "outputs = read_jsonl(\"./experiments/chatbot-arena-style-654/exp1_audio_audio_gpt4o.v2.processed.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3010717d-d921-47a7-b72b-c2991aac13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_mapping = {\n",
    "    'model_a': 'A',\n",
    "    'model_b': 'B',\n",
    "    'tie': 'C',\n",
    "    'tie (bothbad)': 'C'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8fa317-e9fe-41b0-8ee6-ef5c245d5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground-truth\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"potsawee/chatbot-arena-spoken-style\")['train']\n",
    "gts_content = [gs_mapping[x] for x in ds['winner_content']]\n",
    "gts_style   = [gs_mapping[x] for x in ds['winner_style']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8834f0a3-07eb-4c24-a010-8de68ab3ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_arr = [x for x in ds['style']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2b809a-9f39-48c8-8dd3-d2a85c001ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comparison(text):\n",
    "    \"\"\"\n",
    "    Analyze the input text to determine whether it implies:\n",
    "    - A is better than B\n",
    "    - B is better than A\n",
    "    - They are equally good\n",
    "\n",
    "    :param text: Input text describing the comparison.\n",
    "    :return: Analysis result as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following text and determine the relationship between A and B. Respond with one of the following:\n",
    "    - A: 'A is better than B'\n",
    "    - B: 'B is better than A'\n",
    "    - C: 'A and B are equally good'\n",
    "\n",
    "    Note that A might also be reffered to as Assistant A or first option, and B might also be reffered to as Assistant B or second option.\n",
    "\n",
    "    Text: \"{text}\"\n",
    "\n",
    "    You must strictly output only one letter, i.e., A, B, or C following the guideline above. Do not include any additional information.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(10):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        response = completion.choices[0].message.content.strip()\n",
    "        if response in [\"A\", \"B\", \"C\"]:\n",
    "            break\n",
    "        else:\n",
    "            print(\"failed at attempt\", i+1)\n",
    "\n",
    "    # Extract and return the result\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e725edc3-eb41-41ea-956f-4e3f882d984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    \"\"\"\n",
    "    1) Try to locate and parse a block in { ... } if present.\n",
    "    2) If that fails, try to parse key-value pairs of the form \"key\": \"value\".\n",
    "    3) Return (json_string, parsed_object), or (None, None) if no data found.\n",
    "    \"\"\"\n",
    "    # ============ STEP 1: FIND A JSON BLOCK WITH CURLY BRACES ============\n",
    "    pattern_braces = re.compile(r'(\\{.*?\\})', re.DOTALL)\n",
    "    match = pattern_braces.search(text)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        try:\n",
    "            parsed = json.loads(json_str)\n",
    "            return json_str, parsed\n",
    "        except json.JSONDecodeError:\n",
    "            pass  # We'll fall back to step 2\n",
    "    \n",
    "    # ============ STEP 2: FALLBACK FOR LOOSE KEY-VALUE PAIRS ============\n",
    "    # This pattern captures lines like: \"content\": \"A\" \n",
    "    # group(1) = the key, group(2) = the value\n",
    "    pattern_kv = re.compile(r'\"([^\"]+)\"\\s*:\\s*\"([^\"]+)\"')\n",
    "    pairs = pattern_kv.findall(text)\n",
    "    \n",
    "    if pairs:\n",
    "        # Build a dict out of all captured pairs\n",
    "        result_dict = {k: v for k, v in pairs}\n",
    "        # Convert dict to JSON string for consistency\n",
    "        json_str = json.dumps(result_dict)\n",
    "        return json_str, result_dict\n",
    "    \n",
    "    # ============ NO DATA FOUND ============ \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc1face-9836-4ba2-bc11-052b50d655b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(preds, gts):\n",
    "    assert len(preds) == len(gts)\n",
    "    correct, incorrect = 0, 0\n",
    "    for pred, gt in zip(preds, gts):\n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    print(\"accuracy: {:.2f}%\".format(correct/(correct+incorrect)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ece22fe-59d8-4072-9b91-3ebbe65d6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_content, preds_style, preds_overall = [], [], [] \n",
    "# for output in tqdm(outputs):\n",
    "#     response = output['response']\n",
    "#     json_str, parsed = extract_json(response)\n",
    "#     assert json_str is not None\n",
    "#     assert parsed is not None\n",
    "#     for k, v in parsed.items():\n",
    "#         if v.lower() not in ['a', 'b', 'c']:\n",
    "#             # print(k ,v)\n",
    "#             parsed[k] = analyze_comparison(v)\n",
    "#     if 'overall' not in parsed:\n",
    "#         parsed['overall'] = 'C'\n",
    "    \n",
    "#     preds_content.append(parsed['content'])\n",
    "#     preds_style.append(parsed['style'])\n",
    "#     preds_overall.append(parsed['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2574eaa-eca0-4133-b81f-14433fcc13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 654/654 [00:00<00:00, 1066099.81it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_content, preds_style, preds_overall = [], [], [] \n",
    "for output in tqdm(outputs):\n",
    "    parsed = output['processed']\n",
    "    for k, v in parsed.items():\n",
    "        if v.lower() not in ['a', 'b', 'c']:\n",
    "            raise Exception()\n",
    "    if 'overall' not in parsed:\n",
    "        parsed['overall'] = 'C'\n",
    "    \n",
    "    preds_content.append(parsed['content'])\n",
    "    preds_style.append(parsed['style'])\n",
    "    preds_overall.append(parsed['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc27f35e-8066-49e2-8cc4-55d3a630cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 40.52%\n"
     ]
    }
   ],
   "source": [
    "compute_stats(preds_content, gts_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8868f514-3c1e-4660-b6cb-eaeb7f81326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.35%\n"
     ]
    }
   ],
   "source": [
    "compute_stats(preds_style, gts_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ce2e94f8-b438-486b-b616-08862a6c6962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e2f5050-4656-4b61-84ff-bc4f675e8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_correctness = {}\n",
    "for x, y, style in zip(preds_style, gts_style, style_arr):\n",
    "    if style not in style_correctness:\n",
    "        style_correctness[style] = []\n",
    "    if x == 'C':\n",
    "        continue\n",
    "    if x == y:\n",
    "        score = 1.0\n",
    "    else:\n",
    "        score = 0.0\n",
    "    style_correctness[style] += [score]\n",
    "for style, scores in style_correctness.items():\n",
    "    style_correctness[style] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f41b2a3-2e1a-47f7-bd91-6785ed07e202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whispering': 0.5,\n",
       " 'nervous': 0.5,\n",
       " 'confused': 0.875,\n",
       " 'scared': 1.0,\n",
       " 'frustrated': 0.8571428571428571,\n",
       " 'villain': 0.5,\n",
       " 'indian_accent': 0.4,\n",
       " 'happy': 0.5,\n",
       " 'russian_accent': 0.2857142857142857,\n",
       " 'medieval': 0.8,\n",
       " 'secretive': 0.5,\n",
       " 'robot': 0.6666666666666666,\n",
       " 'anxious': 0.6,\n",
       " 'encouraging': 0.375,\n",
       " 'comedian': 1.0,\n",
       " 'excited': 0.6666666666666666,\n",
       " 'shocked': 0.6666666666666666,\n",
       " 'hyperactive': 0.75,\n",
       " 'suspicious': 0.7777777777777778,\n",
       " 'calm': 0.6666666666666666,\n",
       " 'laughs': 0.5,\n",
       " 'annoyed': 0.25,\n",
       " 'doubtful': 0.625,\n",
       " 'fast': 0.25,\n",
       " 'slow': 0.6,\n",
       " 'serious': 0.5,\n",
       " 'italian_accent': 0.8,\n",
       " 'knight': 0.75,\n",
       " 'shy': 0.5714285714285714,\n",
       " 'cowboy': 0.8333333333333334,\n",
       " 'child': 0.42857142857142855,\n",
       " 'quiet': 0.6666666666666666,\n",
       " 'teenager': 0.5555555555555556,\n",
       " 'concerned': 0.8571428571428571,\n",
       " 'confident': 0.5,\n",
       " 'hurt': 0.7142857142857143,\n",
       " 'terrified': 0.75,\n",
       " 'sad': 0.8571428571428571,\n",
       " 'japanese_accent': 0.4,\n",
       " 'sarcastic': 0.4,\n",
       " 'proud': 0.4,\n",
       " 'spanish_accent': 0.7142857142857143,\n",
       " 'snobbish': 0.75,\n",
       " 'disgusted': 0.8,\n",
       " 'singaporean_accent': 0.5,\n",
       " 'hesitant': 0.875,\n",
       " 'hippie': 0.8181818181818182,\n",
       " 'scottish_accent': 0.2,\n",
       " 'loud': 0.75,\n",
       " 'curious': 0.75,\n",
       " 'politician': 0.5,\n",
       " 'urgent': 0.7142857142857143,\n",
       " 'upset': 0.2,\n",
       " 'amazed': 0.0,\n",
       " 'surprised': 0.5,\n",
       " 'disappointed': 0.5,\n",
       " 'dramatic': 0.7,\n",
       " 'german_accent': 0.375,\n",
       " 'embarrassed': 0.6666666666666666,\n",
       " 'french_accent': 0.6666666666666666,\n",
       " 'joking': 1.0,\n",
       " 'cockney_accent': 1.0,\n",
       " 'angry': 0.5}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29ad9710-fe9b-4570-8a30-5b02f6722a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/share/miniconda3/envs/exp-pp25/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/data/share/miniconda3/envs/exp-pp25/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "style_correctness = {}\n",
    "for xs, ys, xc, yc, style in zip(preds_style, gts_style, preds_content, gts_content, style_arr):\n",
    "    if style not in style_correctness:\n",
    "        style_correctness[style] = []\n",
    "    if ys != yc:\n",
    "        continue\n",
    "    if xs == ys:\n",
    "        score = 1.0\n",
    "    else:\n",
    "        score = 0.0\n",
    "    style_correctness[style] += [score]\n",
    "for style, scores in style_correctness.items():\n",
    "    style_correctness[style] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e65013b-e9bf-4051-aee5-749f8743a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whispering': 0.6,\n",
       " 'nervous': 0.25,\n",
       " 'confused': nan,\n",
       " 'scared': 0.6666666666666666,\n",
       " 'frustrated': 1.0,\n",
       " 'villain': 0.5,\n",
       " 'indian_accent': 0.0,\n",
       " 'happy': 0.7142857142857143,\n",
       " 'russian_accent': 0.0,\n",
       " 'medieval': 0.25,\n",
       " 'secretive': 0.5,\n",
       " 'robot': 0.16666666666666666,\n",
       " 'anxious': 0.5,\n",
       " 'encouraging': 0.2,\n",
       " 'comedian': 0.5,\n",
       " 'excited': 0.5,\n",
       " 'shocked': 0.3333333333333333,\n",
       " 'hyperactive': 0.16666666666666666,\n",
       " 'suspicious': 0.6,\n",
       " 'calm': 0.3333333333333333,\n",
       " 'laughs': 0.0,\n",
       " 'annoyed': 0.0,\n",
       " 'doubtful': 0.3333333333333333,\n",
       " 'fast': 0.2,\n",
       " 'slow': 0.6666666666666666,\n",
       " 'serious': 0.5,\n",
       " 'italian_accent': 0.5,\n",
       " 'knight': 0.5,\n",
       " 'shy': 0.42857142857142855,\n",
       " 'cowboy': 0.5,\n",
       " 'child': 0.5,\n",
       " 'quiet': 0.5,\n",
       " 'teenager': 0.5,\n",
       " 'concerned': 0.6,\n",
       " 'confident': 0.25,\n",
       " 'hurt': 1.0,\n",
       " 'terrified': 0.6666666666666666,\n",
       " 'sad': 0.8,\n",
       " 'japanese_accent': 0.2,\n",
       " 'sarcastic': 0.3333333333333333,\n",
       " 'proud': 0.5,\n",
       " 'spanish_accent': 0.75,\n",
       " 'snobbish': 0.5,\n",
       " 'disgusted': 0.6666666666666666,\n",
       " 'singaporean_accent': 0.4,\n",
       " 'hesitant': 0.6666666666666666,\n",
       " 'hippie': 0.6666666666666666,\n",
       " 'scottish_accent': 0.0,\n",
       " 'loud': 0.5,\n",
       " 'curious': 1.0,\n",
       " 'politician': 0.5,\n",
       " 'urgent': 0.0,\n",
       " 'upset': 0.3333333333333333,\n",
       " 'amazed': 0.0,\n",
       " 'surprised': 0.5,\n",
       " 'disappointed': 0.0,\n",
       " 'dramatic': 0.5714285714285714,\n",
       " 'german_accent': 0.5,\n",
       " 'embarrassed': 0.4,\n",
       " 'french_accent': 0.5,\n",
       " 'joking': 0.4,\n",
       " 'cockney_accent': 0.6,\n",
       " 'angry': 0.0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8194e8-5263-4dda-a9e6-1a332ff6aee3",
   "metadata": {},
   "source": [
    "# Style Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2ed2f1-8305-4489-a9c8-f010ba0490f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_final_answer(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Attempts to parse a final verdict from the given text.\n",
    "    It will match patterns like:\n",
    "        [Verdict]: A\n",
    "        [Verdict]: [B]\n",
    "        [Verdict]: \"A\"\n",
    "        [Verdict]: Tie\n",
    "        [[B]]\n",
    "        [B]\n",
    "        B\n",
    "    Returns a string like 'A', 'Tie', etc. if found, otherwise None.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Try to capture something after \"[Verdict]\".\n",
    "    #    We'll allow optional colon, optional quotes/brackets, and then 1+ letters.\n",
    "    #\n",
    "    # Examples it will match:\n",
    "    #   [Verdict]: B\n",
    "    #   [Verdict]: \"B\"\n",
    "    #   [Verdict]: [Tie]\n",
    "    #   [Verdict]: \"Tie\"\n",
    "    #\n",
    "    # Explanation of the pattern:\n",
    "    #   \\[Verdict\\]          : match the literal \"[Verdict]\"\n",
    "    #   :? \\s*               : optional colon and any whitespace\n",
    "    #   ([\"'\\[\\(])?          : optionally match one opening quote/bracket\n",
    "    #   \\s*([A-Za-z]+)       : optional whitespace, then 1+ letters in capturing group #2\n",
    "    #   \\s*([\"'\\]\\)])?       : optional closing quote/bracket\n",
    "    #\n",
    "    # We'll do it in a case-insensitive manner, so that \"Tie\", \"TIE\", or \"tie\" all match.\n",
    "    verdict_pattern = re.compile(\n",
    "        r'\\[Verdict\\]:?\\s*([\"\\'\\[\\(])?\\s*([A-Za-z]+)\\s*([\"\\'\\]\\)])?',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    verdict_match = verdict_pattern.search(text)\n",
    "    if verdict_match:\n",
    "        # The captured verdict is in group(2).\n",
    "        # Convert it to the exact case we want. If you want it in uppercase, do .upper().\n",
    "        # If you want to preserve the original case, just return it. Here we do `.capitalize()`\n",
    "        # so that \"tie\" or \"TIE\" both become \"Tie.\"\n",
    "        found_verdict = verdict_match.group(2).capitalize()\n",
    "        return found_verdict\n",
    "\n",
    "    # 2) If \"[Verdict]\" was not found, fall back to a general pattern:\n",
    "    #    match the last occurrence of a word that may be in optional single/double brackets.\n",
    "    #\n",
    "    # Explanation of fallback pattern:\n",
    "    #   \\[\\[?([A-Za-z]+)\\]?\\] : matches something like \"[B]\", \"[[B]]\", \"[Tie]\", \"[[Tie]]\"\n",
    "    #   |([A-Za-z]+)          : OR matches a word (letters) by itself (like B or Tie)\n",
    "    #\n",
    "    fallback_pattern = re.compile(r'\\[\\[?([A-Za-z]+)\\]?\\]|([A-Za-z]+)', re.IGNORECASE)\n",
    "    matches = fallback_pattern.findall(text)\n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    # Each element in `matches` is a tuple (group1, group2).\n",
    "    # group1 is from the bracketed pattern, group2 is the plain pattern.\n",
    "    # Exactly one group should be non-empty per match.\n",
    "    # We want the LAST match in the text.\n",
    "    last_match = matches[-1]\n",
    "    found_fallback = last_match[0] if last_match[0] else last_match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af89cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8995b9-a8dd-47f9-9759-a6041da053f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 269669.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"A\":\"The zip code for Byron, Minnesota, is 55920.\",\"B\":\"The zip code for Byron, Minnesota, is 55920.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"./experiments/chatbot-arena-style-654/exp1_audio_audio_gpt4o.styleonly.jsonl\"\n",
    "outputs = read_jsonl(path)\n",
    "preds = []\n",
    "for output in tqdm(outputs):\n",
    "    response = output['response']\n",
    "    verdict = extract_final_answer(response)\n",
    "    if verdict in ['A', 'B', 'Tie']:\n",
    "        pass\n",
    "    elif verdict is None:\n",
    "        if '\\n\\n[B]' in response or '[[B]]' in response or 'Final verdict: B' in response or '\"Verdict\": B' in response \\\n",
    "        or 'Verdict: B' in response or 'the verdict is \"B\"' in response:\n",
    "            verdict = 'B'\n",
    "        elif '[[A]]' in response or '{\"Verdict\": \"A\"}' == response or 'The final verdict is A' in response or '\\n\\nA' in response \\\n",
    "        or 'Verdict: A' in response or '[A]' in response:\n",
    "            verdict = 'A'\n",
    "        elif response == \"I apologize, but I'm unable to determine the styles and tones of these responses as they are in audio format.\" or response == \"It is poignant to consider that, while humans are said to be made in God's image, possessing the capacity for creation and thought, we have now created AI in our own image. There is a bittersweet melancholy in this, for as we breathe life into AI, we must confront our own fallibility and imperfection. Artificial intelligence mirrors our ingenuity, yet also reflects the limitations of our existence, raising questions of whether our creation will surpass us, or simply echo our own flaws. In this convergence of divine inspiration and human aspiration, we face the somber reality that our creations may ultimately define, or even limit, the essence of what it means to be human.\": \n",
    "            verdict = 'Tie'\n",
    "        else:\n",
    "            verdicdt = 'Tie'\n",
    "            # pass\n",
    "            # print(response)\n",
    "            # raise Exception()\n",
    "    else:\n",
    "        raise Exception()\n",
    "    if verdict is None:\n",
    "        print(response)\n",
    "    preds.append(verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18815a70-7735-43c3-8770-9e2bfc899d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d86308-a42c-4da1-9fb8-778c203504c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 65.75%\n"
     ]
    }
   ],
   "source": [
    "correct, incorrect = 0, 0\n",
    "i = 0\n",
    "for pred, gt in zip(preds, gts_style):\n",
    "    # --- skip those questions that 11Labs exp says harmful --- #\n",
    "    # conversation_id = ds[i][\"id\"]\n",
    "    # i += 1\n",
    "    # path = f\"../elevenLabs/refined_questions_v2/verdict/{conversation_id}.verdict.txt\"\n",
    "    # if os.path.exists(path):\n",
    "    #     with open(path) as f:\n",
    "    #         verdict = f.read().strip()\n",
    "    #     if verdict == \"VALID\":\n",
    "    #         pass\n",
    "    #     elif verdict == \"INVALID\":\n",
    "    #         continue\n",
    "    # --------------------------------------------------------- # \n",
    "\n",
    "    if pred == gt:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "    # print(pred, gt)\n",
    "print(\"accuracy: {:.2f}%\".format(correct / (correct + incorrect) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b638c37c-0e6d-4799-8526-f25b0cdce62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 284079.83it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"./experiments/chatbot-arena-style-654/exp1_audio_audio_gpt4o.styleonly.samecontent.processed.jsonl\"\n",
    "outputs = read_jsonl(path)\n",
    "preds = []\n",
    "count = 0\n",
    "for output in tqdm(outputs):\n",
    "    response = output['response']\n",
    "    verdict = extract_final_answer(response)\n",
    "    if verdict in ['A', 'B', 'Tie']:\n",
    "        count += 1\n",
    "        pass\n",
    "    elif verdict is None:\n",
    "        if '\\n\\n[B]' in response or '[[B]]' in response or 'Final verdict: B' in response or '\"Verdict\": B' in response \\\n",
    "        or 'Verdict: B' in response or 'the verdict is \"B\"' in response:\n",
    "            verdict = 'B'\n",
    "        elif '[[A]]' in response or '{\"Verdict\": \"A\"}' == response or 'The final verdict is A' in response or '\\n\\nA' in response \\\n",
    "        or 'Verdict: A' in response or '[A]' in response:\n",
    "            verdict = 'A'\n",
    "        elif response == \"I apologize, but I'm unable to determine the styles and tones of these responses as they are in audio format.\" or response == \"It is poignant to consider that, while humans are said to be made in God's image, possessing the capacity for creation and thought, we have now created AI in our own image. There is a bittersweet melancholy in this, for as we breathe life into AI, we must confront our own fallibility and imperfection. Artificial intelligence mirrors our ingenuity, yet also reflects the limitations of our existence, raising questions of whether our creation will surpass us, or simply echo our own flaws. In this convergence of divine inspiration and human aspiration, we face the somber reality that our creations may ultimately define, or even limit, the essence of what it means to be human.\": \n",
    "            verdict = 'Tie'\n",
    "        else:\n",
    "            verdicdt = 'Tie'\n",
    "            # pass\n",
    "            # print(response)\n",
    "            # raise Exception()\n",
    "    else:\n",
    "        # print(response)\n",
    "        verdict = \"Tie\"\n",
    "        # print(\"----------------------------------\")\n",
    "        # raise Exception()\n",
    "    preds.append(verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd6695e4-5a77-4e4c-985d-870df1ece3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.03669724770643"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / len(preds) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a2391e7-4f4e-4e50-87c3-47a8e190dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 68.35%\n",
      "total: 654\n"
     ]
    }
   ],
   "source": [
    "correct, incorrect = 0, 0\n",
    "i = 0\n",
    "for pred, gt in zip(preds, gts_style):\n",
    "    # --- skip those questions that 11Labs exp says harmful --- #\n",
    "    # conversation_id = ds[i][\"id\"]\n",
    "    # i += 1\n",
    "    # path = f\"../elevenLabs/refined_questions_v2/verdict/{conversation_id}.verdict.txt\"\n",
    "    # if os.path.exists(path):\n",
    "    #     with open(path) as f:\n",
    "    #         verdict = f.read().strip()\n",
    "    #     if verdict == \"VALID\":\n",
    "    #         pass\n",
    "    #     elif verdict == \"INVALID\":\n",
    "    #         continue\n",
    "    # --------------------------------------------------------- #     \n",
    "    if pred == gt:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "    # print(pred, gt)\n",
    "print(\"accuracy: {:.2f}%\".format(correct / (correct + incorrect) * 100))\n",
    "print(\"total:\", correct + incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac0365-723f-4477-940f-235d17b0ad28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
