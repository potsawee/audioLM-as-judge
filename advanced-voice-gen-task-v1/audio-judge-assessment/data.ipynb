{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "560db354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from datasets import load_dataset, Audio, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e938e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e49c3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/workspace/ppotsawee/audioLM-as-judge-new/advanced-voice-gen-task-v1/questions1_shuffled_id.json\"\n",
    "with open(path) as f:\n",
    "    instructions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "664d33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping = {\n",
    "    \"diva+tts\": \"diva/text_kokoro\",\n",
    "    \"gemini1.5-flash+tts\": \"gemini15flash-api/text_kokoro_tts\",\n",
    "    \"gemini2-flash+tts\": \"gemini2flash-api/text_kokoro_tts\",\n",
    "    \"gemini2-flash-exp\": \"gemini2flash-exp/audio\",\n",
    "    \"gpt4o\": \"gpt4o/audio\",\n",
    "    \"moshi\": \"moshi/audio\",\n",
    "    \"qwen2-audio+tts\": \"qwen2/text_kokoro\",\n",
    "    \"typhoon2-audio\": \"typhoon2/audio\"\n",
    "}\n",
    "\n",
    "base_path = \"/data/workspace/ppotsawee/audioLM-as-judge-new/eval-leaderboard/experiments/advvoiceq1\"\n",
    "\n",
    "candidates1 = [\n",
    "    \"diva+tts\",\n",
    "    \"gemini1.5-flash+tts\",\n",
    "    \"gemini2-flash+tts\",\n",
    "    \"gemini2-flash-exp\",\n",
    "    \"moshi\",\n",
    "    \"qwen2-audio+tts\",\n",
    "    \"typhoon2-audio\"\n",
    "]\n",
    "\n",
    "\n",
    "# Add a weight for every model (default 1 if you don't mention it)\n",
    "candidate_weights1 = {\n",
    "    \"diva+tts\": 1,\n",
    "    \"gemini1.5-flash+tts\": 1,\n",
    "    \"gemini2-flash+tts\": 1,\n",
    "    \"gemini2-flash-exp\": 9,\n",
    "    \"moshi\": 1,\n",
    "    \"qwen2-audio+tts\": 1,\n",
    "    \"typhoon2-audio\": 1\n",
    "}\n",
    "\n",
    "# Build the weights list in the same order as `candidates`\n",
    "weights1 = [candidate_weights1.get(m, 1) for m in candidates1]\n",
    "\n",
    "def draw_example1(idx):\n",
    "\n",
    "    model_a = \"gpt4o\"\n",
    "\n",
    "    # # Use `random.choices` (plural) to draw with the given weights\n",
    "    # model_b = random.choices(candidates1, weights=weights1, k=1)[0]\n",
    "    model_b = \"gemini2-flash-exp\"\n",
    "\n",
    "    # swap 50% chance\n",
    "    if random.random() < 0.5:\n",
    "        model_a, model_b = model_b, model_a\n",
    "\n",
    "    wav_path_a = f\"{base_path}/{model_mapping[model_a]}/{idx}.wav\"\n",
    "    wav_path_b = f\"{base_path}/{model_mapping[model_b]}/{idx}.wav\"\n",
    "\n",
    "    # check if the wav files exist\n",
    "    assert os.path.exists(wav_path_a), f\"File not found: {wav_path_a}\"\n",
    "    assert os.path.exists(wav_path_b), f\"File not found: {wav_path_b}\"\n",
    "\n",
    "    pair = {\n",
    "        \"model_a\": model_a,\n",
    "        \"model_b\": model_b,\n",
    "        \"wav_path_a\": wav_path_a,\n",
    "        \"wav_path_b\": wav_path_b,\n",
    "        \"instruction\": instructions[idx][\"question\"],\n",
    "        \"idx\": idx\n",
    "    }\n",
    "    return pair\n",
    "\n",
    "candidates2 = [\n",
    "    \"diva+tts\",\n",
    "    \"gemini1.5-flash+tts\",\n",
    "    \"gemini2-flash+tts\",\n",
    "    \"moshi\",\n",
    "    \"qwen2-audio+tts\",\n",
    "    \"typhoon2-audio\"\n",
    "]\n",
    "\n",
    "\n",
    "def draw_example2(idx):\n",
    "    if random.random() < 0.5:\n",
    "        model_a = \"gpt4o\"\n",
    "    else:\n",
    "        model_a = \"gemini2-flash-exp\"\n",
    "\n",
    "    # Use `random.choices` (plural) to draw with the given weights\n",
    "    model_b = random.choices(candidates2, k=1)[0]\n",
    "\n",
    "    # swap 50% chance\n",
    "    if random.random() < 0.5:\n",
    "        model_a, model_b = model_b, model_a\n",
    "\n",
    "    wav_path_a = f\"{base_path}/{model_mapping[model_a]}/{idx}.wav\"\n",
    "    wav_path_b = f\"{base_path}/{model_mapping[model_b]}/{idx}.wav\"\n",
    "\n",
    "    # check if the wav files exist\n",
    "    assert os.path.exists(wav_path_a), f\"File not found: {wav_path_a}\"\n",
    "    assert os.path.exists(wav_path_b), f\"File not found: {wav_path_b}\"\n",
    "\n",
    "    pair = {\n",
    "        \"model_a\": model_a,\n",
    "        \"model_b\": model_b,\n",
    "        \"wav_path_a\": wav_path_a,\n",
    "        \"wav_path_b\": wav_path_b,\n",
    "        \"instruction\": instructions[idx][\"question\"],\n",
    "        \"idx\": idx\n",
    "    }\n",
    "    return pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e16eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_a': 'gpt4o',\n",
       " 'model_b': 'gemini2-flash-exp',\n",
       " 'wav_path_a': '/data/workspace/ppotsawee/audioLM-as-judge-new/eval-leaderboard/experiments/advvoiceq1/gpt4o/audio/0.wav',\n",
       " 'wav_path_b': '/data/workspace/ppotsawee/audioLM-as-judge-new/eval-leaderboard/experiments/advvoiceq1/gemini2flash-exp/audio/0.wav',\n",
       " 'instruction': \"Say the word 'tomato' twice starting with a British pronunciation version, then an American pronunciation version, and teach me the difference.\",\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_example1(idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "210abc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_a': 'gemini2-flash-exp',\n",
       " 'model_b': 'diva+tts',\n",
       " 'wav_path_a': '/data/workspace/ppotsawee/audioLM-as-judge-new/eval-leaderboard/experiments/advvoiceq1/gemini2flash-exp/audio/0.wav',\n",
       " 'wav_path_b': '/data/workspace/ppotsawee/audioLM-as-judge-new/eval-leaderboard/experiments/advvoiceq1/diva/text_kokoro/0.wav',\n",
       " 'instruction': \"Say the word 'tomato' twice starting with a British pronunciation version, then an American pronunciation version, and teach me the difference.\",\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_example2(idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2b628595",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_wav_base = \"/data/workspace/ppotsawee/audioLM-as-judge-new/advanced-voice-gen-task-v1/questions1_kokoro_wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "71819c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = []\n",
    "for idx in range(len(instructions)):\n",
    "    ex1 = draw_example1(idx)\n",
    "\n",
    "    mydata.append({\n",
    "        \"idx\": f\"{idx}_{0}\",\n",
    "        \"instruction\": f\"{instruction_wav_base}/{idx}.kokoro.wav\",\n",
    "        \"audio_a\": ex1[\"wav_path_a\"],\n",
    "        \"audio_b\": ex1[\"wav_path_b\"],\n",
    "        \"instruction_text\": instructions[idx][\"question\"],\n",
    "        \"model_a\": ex1[\"model_a\"],\n",
    "        \"model_b\": ex1[\"model_b\"],\n",
    "    })\n",
    "\n",
    "    while True:\n",
    "        ex2 = draw_example2(idx)\n",
    "        if ex2[\"model_a\"] != ex1[\"model_a\"] and ex2[\"model_b\"] != ex1[\"model_b\"]:\n",
    "            break\n",
    "    \n",
    "    mydata.append({\n",
    "        \"idx\": f\"{idx}_{1}\",\n",
    "        \"instruction\": f\"{instruction_wav_base}/{idx}.kokoro.wav\",\n",
    "        \"audio_a\": ex2[\"wav_path_a\"],\n",
    "        \"audio_b\": ex2[\"wav_path_b\"],\n",
    "        \"instruction_text\": instructions[idx][\"question\"],\n",
    "        \"model_a\": ex2[\"model_a\"],\n",
    "        \"model_b\": ex2[\"model_b\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9fd67434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5a1d6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data = Dataset.from_list(mydata)\n",
    "hf_data = hf_data.cast_column(\"instruction\", Audio()).cast_column(\"audio_a\", Audio()).cast_column(\"audio_b\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc711b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1dffd2afd94034ba847677b1c44665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6ed941a854067a00a3f4b2fb64c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ebbfa4016f478483215ff1471e07c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a457611bac544f29c8e30daf84d52c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/potsawee/speakbench-v1-nolabel/commit/4f24ae3b4117f7621cd10c4fcc0df2bff988cf7b', commit_message='Upload dataset', commit_description='', oid='4f24ae3b4117f7621cd10c4fcc0df2bff988cf7b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/potsawee/speakbench-v1-nolabel', endpoint='https://huggingface.co', repo_type='dataset', repo_id='potsawee/speakbench-v1-nolabel'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hf_data.push_to_hub(\"potsawee/speakbench-v1-nolabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83709f64",
   "metadata": {},
   "source": [
    "## Add annotations / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc36d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=\"\"\"\n",
    "b\n",
    "b\n",
    "b\n",
    "a\n",
    "both_good\n",
    "a\n",
    "a\n",
    "a\n",
    "a\n",
    "a\n",
    "b\n",
    "a\n",
    "a\n",
    "a\n",
    "a\n",
    "a\n",
    "b\n",
    "b\n",
    "b\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "a\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "b\n",
    "a\n",
    "b\n",
    "b\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "both_bad\n",
    "both_bad\n",
    "b\n",
    "b\n",
    "b\n",
    "both_good\n",
    "a\n",
    "a\n",
    "b\n",
    "b\n",
    "both_bad\n",
    "a\n",
    "a\n",
    "a\n",
    "b\n",
    "a\n",
    "both_bad\n",
    "both_good\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "b\n",
    "a\n",
    "both_bad\n",
    "both_bad\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "a\n",
    "both_bad\n",
    "both_good\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "b\n",
    "a\n",
    "both_bad\n",
    "b\n",
    "both_bad\n",
    "a\n",
    "a\n",
    "both_bad\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "both_good\n",
    "a\n",
    "b\n",
    "b\n",
    "a\n",
    "a\n",
    "both_bad\n",
    "b\n",
    "a\n",
    "b\n",
    "b\n",
    "a\n",
    "a\n",
    "b\n",
    "a\n",
    "b\n",
    "b\n",
    "b\n",
    "a\n",
    "a\n",
    "b\n",
    "both_bad\n",
    "b\n",
    "b\n",
    "b\n",
    "a\n",
    "b\n",
    "both_good\n",
    "both_good\n",
    "a\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "both_good\n",
    "a\n",
    "both_bad\n",
    "both_bad\n",
    "both_good\n",
    "a\n",
    "both_bad\n",
    "b\n",
    "both_bad\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "b\n",
    "a\n",
    "both_bad\n",
    "a\n",
    "b\n",
    "both_bad\n",
    "a\n",
    "a\n",
    "b\n",
    "b\n",
    "both_bad\n",
    "both_bad\n",
    "a\n",
    "a\n",
    "a\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7133e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labels) 164\n"
     ]
    }
   ],
   "source": [
    "labels = [x.strip() for x in labels.strip().split(\"\\n\")]\n",
    "print(\"len(labels)\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553f427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e039564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'instruction', 'audio_a', 'audio_b', 'instruction_text', 'model_a', 'model_b'],\n",
       "    num_rows: 164\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"potsawee/speakbench-v1-nolabel\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8586264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idx', 'instruction', 'audio_a', 'audio_b', 'label', 'instruction_text', 'model_a', 'model_b']\n"
     ]
    }
   ],
   "source": [
    "assert len(labels) == len(ds), \"labels length must equal dataset length\"\n",
    "\n",
    "# 3. Add the column\n",
    "ds = ds.add_column(\"label\", labels)     # the Dataset object is immutable ⇒ assign back\n",
    "\n",
    "# 4. (Optional) sanity-check\n",
    "# print(ds)\n",
    "# print(ds[0])        # first row now has a \"label\" field\n",
    "\n",
    "new_order = [\n",
    "    \"idx\",\n",
    "    \"instruction\",\n",
    "    \"audio_a\",\n",
    "    \"audio_b\",           # want \"label\" immediately after this\n",
    "    \"label\",\n",
    "    \"instruction_text\",\n",
    "    \"model_a\",\n",
    "    \"model_b\",\n",
    "]\n",
    "\n",
    "# 2️⃣  create a reordered copy\n",
    "ds = ds.select_columns(new_order)\n",
    "\n",
    "print(ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45274c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'instruction', 'audio_a', 'audio_b', 'label', 'instruction_text', 'model_a', 'model_b'],\n",
       "    num_rows: 164\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c055f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6071bcf1c9784feb9749bed8d7297620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb2fa89dce740b0bbed5e36efc2e1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481edf324be84909ac2143cab8fd3375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/potsawee/speakbench-v1-label/commit/f6da5391a1ab176d5af448d5ff719acddb85045d', commit_message='Upload dataset', commit_description='', oid='f6da5391a1ab176d5af448d5ff719acddb85045d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/potsawee/speakbench-v1-label', endpoint='https://huggingface.co', repo_type='dataset', repo_id='potsawee/speakbench-v1-label'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"potsawee/speakbench-v1-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b3a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-pp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
